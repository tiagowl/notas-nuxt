# Sistema de Gerenciamento de Notas

Sistema de gerenciamento de notas hier√°rquico constru√≠do com Nuxt 4, Vue 3, Prisma, e integra√ß√£o com Hugging Face AI.

## üöÄ Come√ßando

### Pr√©-requisitos

- Node.js v18.x ou superior
- npm v9.x ou superior (ou yarn/pnpm)
- PostgreSQL (Neon database)
- Conta Hugging Face com API Key

### Instala√ß√£o

1. **Entre no diret√≥rio do frontend**
```bash
cd src/frontend
```

2. **Instale as depend√™ncias**
```bash
npm install
```

3. **Configure as vari√°veis de ambiente**
```bash
cp .env.example .env
```

Edite `.env` na raiz do reposit√≥rio (ou em `src/frontend` se existir) e configure:
```env
DATABASE_URL="postgresql://user:password@host:port/database?sslmode=require"
HUGGING_FACE_API_KEY="hf_xxxxxxxxxxxx"
# Opcional: Modelo de IA (padr√£o: openai-community/gpt2)
# Para melhores resultados, use modelos instrucionais como:
# - mistralai/Mistral-7B-Instruct-v0.2 (melhor qualidade, pode exigir token pago)
# - google/flan-t5-base (bom para instru√ß√µes)
# - microsoft/DialoGPT-large (di√°logo)
HUGGING_FACE_MODEL="openai-community/gpt2"
NODE_ENV="development"
NUXT_PUBLIC_APP_URL="http://localhost:3000"
```

**Nota sobre modelos de IA:**
- O modelo padr√£o (GPT-2) √© limitado e pode gerar textos menos coerentes
- Para melhores resultados, configure um modelo instrucional via `HUGGING_FACE_MODEL`
- Alguns modelos podem exigir tokens pagos no Hugging Face
- Verifique a disponibilidade dos modelos no Router: https://huggingface.co/inference-api

4. **Configure o banco de dados** (execute de dentro de `src/frontend`)
```bash
# Gerar Prisma Client
npx prisma generate

# Rodar migrations
npx prisma migrate dev
```

5. **Inicie o servidor de desenvolvimento**
```bash
npm run dev
```

Acesse: `http://localhost:3000`

## üìÅ Estrutura do Projeto (src/frontend)

```
src/frontend/
‚îú‚îÄ‚îÄ package.json         # Depend√™ncias e scripts
‚îú‚îÄ‚îÄ nuxt.config.ts       # Configura√ß√£o Nuxt
‚îú‚îÄ‚îÄ prisma/              # Prisma schema e migrations
‚îú‚îÄ‚îÄ server/              # API routes (markers, sub-markers, notes, ai)
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îú‚îÄ‚îÄ components/          # Componentes Vue
‚îú‚îÄ‚îÄ composables/         # Composables
‚îú‚îÄ‚îÄ pages/               # Nuxt pages (auto-routes)
‚îú‚îÄ‚îÄ stores/              # Pinia stores
‚îú‚îÄ‚îÄ types/               # TypeScript types
‚îú‚îÄ‚îÄ utils/               # Fun√ß√µes utilit√°rias
‚îî‚îÄ‚îÄ assets/              # CSS e assets
```

## üõ†Ô∏è Stack Tecnol√≥gica

- **Framework**: Nuxt 4
- **Frontend**: Vue 3 + TypeScript
- **UI**: Tailwind CSS
- **State**: Pinia
- **ORM**: Prisma
- **Database**: Neon PostgreSQL
- **Editor**: TipTap
- **AI**: Hugging Face API
- **Validation**: Zod
- **Sanitization**: DOMPurify

## ü§ñ Dicas para Gera√ß√£o de Conte√∫do com IA

Para obter melhores resultados ao gerar conte√∫do:

### Prompts Efetivos
- **Seja espec√≠fico**: Inclua tema, p√∫blico-alvo, tom e formato desejado
- **Forne√ßa contexto**: Explique o prop√≥sito do texto (resumo, explica√ß√£o, tutorial, etc.)
- **Mencione exemplos**: Se relevante, pe√ßa exemplos pr√°ticos ou estudos de caso
- **Defina estrutura**: Para textos longos, sugira se√ß√µes ou subt√≥picos

### Exemplo de Prompt Eficaz
```
Escreva um resumo sobre derivadas parciais explicando: 
o que s√£o, como calcular e suas aplica√ß√µes pr√°ticas 
em problemas de otimiza√ß√£o. Use linguagem acess√≠vel 
para estudantes universit√°rios e inclua um exemplo pr√°tico.
```

### Modelos Recomendados

**Importante**: Nem todos os modelos est√£o dispon√≠veis via Inference Providers do Hugging Face. Use modelos que estejam marcados como "Deployed by Inference Provider" no Hugging Face Hub.

**Modelos recomendados para seguir instru√ß√µes bem (estilo ChatGPT)**:

1. **Llama 3.1 8B Instruct** (`meta-llama/Llama-3.1-8B-Instruct`) - ‚≠ê **Melhor para seguir instru√ß√µes** - Muito bom em seguir comandos espec√≠ficos
2. **Mistral-7B-Instruct** (`mistralai/Mistral-7B-Instruct-v0.2`) - Bom para instru√ß√µes gerais
3. **GPT-2** (`openai-community/gpt2`) - B√°sico, mas amplamente dispon√≠vel (n√£o segue instru√ß√µes t√£o bem)

‚ö†Ô∏è **Modelos que podem n√£o estar dispon√≠veis**:
- `google/flan-t5-base` - N√£o est√° implantado por Inference Providers (pode dar erro 404)
- `microsoft/DialoGPT-large` - Verificar disponibilidade

**Dica**: Para melhor qualidade de resposta √†s suas instru√ß√µes, use `meta-llama/Llama-3.1-8B-Instruct`.

Configure via `HUGGING_FACE_MODEL` no `.env`:
```env
HUGGING_FACE_MODEL=meta-llama/Llama-3.1-8B-Instruct
```

Para verificar se um modelo est√° dispon√≠vel, visite a p√°gina do modelo no [Hugging Face Hub](https://huggingface.co/models) e procure por "Deployed by Inference Provider".

### Configura√ß√£o da API Key

**Importante**: Para evitar erros 404, certifique-se de:

1. **Token com permiss√µes corretas**: 
   - Acesse [Hugging Face Settings ‚Üí Access Tokens](https://huggingface.co/settings/tokens)
   - Crie um token do tipo **"Fine-grained"** ou use um token **"Read"** que tenha permiss√£o para Inference API
   - Tokens antigos podem n√£o ter as permiss√µes necess√°rias

2. **Modelo dispon√≠vel**:
   - Verifique se o modelo est√° dispon√≠vel para infer√™ncia na p√°gina do modelo no Hugging Face Hub
   - Alguns modelos podem estar temporariamente indispon√≠veis ou requerer permiss√µes especiais

3. **Verificar vari√°veis de ambiente**:
   ```env
   HUGGING_FACE_API_KEY=seu_token_aqui
   HUGGING_FACE_MODEL=openai-community/gpt2  # Opcional, padr√£o √© gpt2
   ```

## üìö Documenta√ß√£o

Documenta√ß√£o completa dispon√≠vel em:
- `outputs/product-owner/` - Requisitos e User Stories
- `outputs/architect/` - Arquitetura e decis√µes t√©cnicas
- `outputs/ux/` - Wireframes e prot√≥tipos

## üß™ Testes

```bash
npm run test
```

## üì¶ Build

```bash
npm run build
```

## üö¢ Deploy

O projeto est√° pronto para deploy em plataformas que suportam Nuxt:
- Vercel
- Netlify
- Render

Configure as vari√°veis de ambiente no painel de deploy.

## üìù Licen√ßa

MIT
